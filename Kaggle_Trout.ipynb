{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SI 670 Fall 2020 Kaggle Competition**\n",
    "\n",
    "Please form teams of up to 4 students.  You should not collaborate with other teams, but you can talk to the GSIs if you are really stuck.  Please record you teams here:  https://docs.google.com/spreadsheets/d/1TDm_bwdSnENU8AMzxjvgqP2Fo3Poi3nRGr8dP1iIbqs/edit?usp=drive_web&ouid=109090332886082450282\n",
    "\n",
    "For those who filled out the team survey and asked to be assigned to a team, you should find your name and your team members in the Google Sheet above. Please feel free to let us know if we missed you.\n",
    "\n",
    "Give your team a fun and exciting name for the competition.  You only need one submission for the team.  Everyone on the team will get the same score.  \n",
    "\n",
    "\n",
    "**Scoring**\n",
    "\n",
    "There are two tasks, but they will be scored together.  It will be scored out of 100 points.  \n",
    "You shall receive 40 points for a successful submission.  \n",
    "You shall receive 20 additional points for attaining benchmark #1.\n",
    "You shall receive 10 additional points for attaining benchmark #2.\n",
    "You shall receive 30 * 2 / log2(2 + rank) additional “ranking points”.\n",
    "The top five teams after the first evaluation will receive an additional 5 points.  \n",
    "\n",
    "Note that, if you attain both benchmarks, you are guaranteed a score of 82.  The winning team will receive 108 points. \n",
    "\n",
    "The competition shall start Tuesday 10/20.\n",
    "\n",
    "First evaluation is Monday 10/26 at 11:59pm  (only used for 5 bonus points)\n",
    "\n",
    "Final evaluation is Monday 11/2 at 11:59 pm   \n",
    "\n",
    "**Context**\n",
    "\n",
    "Lake monitoring provides important information for environment protection and pollution identification, such as temperature/thermal monitoring. In this Kaggle task, we will provide thermal sensor data for multiple lakes and ask you to predict/estimate the temperature at a certain depth for certain lakes.\n",
    "\n",
    "Content\n",
    "We provide Lake Trout’s data during the period of Apr 20th, 2012 - Apr 19th, 2018.\n",
    "\n",
    "For your reference, we also provide the data of six other lakes (ie., Bear Head, Carlos, Elk, Pearl, Shaokotan, White Iron). Please note that these datasets may vary in terms of the time window (yes, this is how real-world datasets look like!)\n",
    "\n",
    "For each lake, there will be multiple sensors at different depths, and we will provide lake_id, time, depth and the corresponding temperature at this depth and time point. For example, for the Shaokotan Lake, you will see the following columns, with LakeId representing the lake identifier, Date_time representing the time stamp, Depth_m representing the depth in meters, and Water_Temp_C representing the temperature in Celsius.  Please note that the number of sensors are different across different lakes. \n",
    "\n",
    "\n",
    "**Task**\n",
    "\n",
    "Predicting/estimating the temperature of Trout Lake at depth 10.5 m during Apr 20th, 2018 - Apr 19th, 2019. Please feel free to use part of/all the data we provide. \n",
    "\n",
    "Benchmark 1:  MSE < 0.065\n",
    "Benchmark 2:  MSE < 0.032\n",
    "\n",
    "Files for first task\n",
    "For the first task, we will provide you a file Trout_training.csv under the Trout folder which contains all the sensors in the Trout Lake as training. Besides, we will give you another Trout_testing_features.csv under the Trout folder which contains all other sensors’ temperature (except the depth 10.5’s temperature). \n",
    "\n",
    "We hope you return a file named Trout_prediction.csv, the dataset you return and upload should have two columns: Date_Time and Water_Temp_C, with a shape of 8,760 * 2. (Reason for 8,760: 8,760 =  365 days * 24 sensorings/day) You are supposed to predict every hour’s temperature of depth-10.5 sensor during  Apr 20th, 2018 - Apr 19th, 2019. \n",
    "\n",
    "**Link** \n",
    "https://www.kaggle.com/c/si670fall2020/overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_Time</th>\n",
       "      <th>Water_Temp_C</th>\n",
       "      <th>Depth_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.687</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.577</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.687</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.687</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.687</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.632</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.715</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.770</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.825</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-12-01 00:00:00</td>\n",
       "      <td>0.742</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date_Time  Water_Temp_C  Depth_m\n",
       "0  2013-12-01 00:00:00         0.687      1.5\n",
       "1  2013-12-01 00:00:00         0.577      2.5\n",
       "2  2013-12-01 00:00:00         0.687      3.5\n",
       "3  2013-12-01 00:00:00         0.687      4.5\n",
       "4  2013-12-01 00:00:00         0.687      5.5\n",
       "5  2013-12-01 00:00:00         0.632      6.5\n",
       "6  2013-12-01 00:00:00         0.715      7.5\n",
       "7  2013-12-01 00:00:00         0.770      8.5\n",
       "8  2013-12-01 00:00:00         0.825      9.5\n",
       "9  2013-12-01 00:00:00         0.742     10.5"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as py\n",
    "\n",
    "df_trout = pd.read_csv('Greenwood_training.csv')\n",
    "df_trout.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trout.Date_Time = pd.to_datetime(df_trout.Date_Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_trout['Water_Temp_C'] = df_trout['Water_Temp_C'].apply(lambda x: np.round(x,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_trout = df_trout[(df_trout['Date_Time'] >= '2016-04-20') & (df_trout['Date_Time'] <= '2018-04-19')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "month = pd.DatetimeIndex(df_trout.Date_Time).month\n",
    "df_trout['Month'] = month\n",
    "\n",
    "# year = pd.DatetimeIndex(df_trout['Date_Time']).year\n",
    "# df_trout['Year'] = year\n",
    "\n",
    "# #Extract Hour out of Date_Time\n",
    "# hour = pd.DatetimeIndex(df_trout['Date_Time']).hour\n",
    "# df_trout['Hour'] = hour\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date_Time', 'Water_Temp_C', 'Depth_m', 'Month'], dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trout.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=699842, step=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trout.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [1,2,3,10,11,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trout = df_trout.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=df_trout[df_trout['Month']==12]\n",
    "x=df_trout[df_trout['Month']!=12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[['Date_Time', 'Water_Temp_C', 'Depth_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[['Date_Time', 'Water_Temp_C', 'Depth_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = unstacked[10.5]\n",
    "# x = unstacked[lists]\n",
    "unstacked_x = x.pivot(index='Date_Time', columns='Depth_m', values='Water_Temp_C')\n",
    "# unstacked_x = unstacked_x.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "unstacked_y = y.pivot(index='Date_Time', columns='Depth_m', values='Water_Temp_C')\n",
    "# unstacked_y = unstacked_y.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-380871d62e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_poly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munstacked_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m         \"\"\"\n\u001b[0;32m-> 1508\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1509\u001b[0m         combinations = self._combinations(n_features, self.degree,\n\u001b[1;32m   1510\u001b[0m                                           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteraction_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=4)\n",
    "X_poly = poly.fit_transform(unstacked_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [31717, 2964]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-07e42cc7c321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_poly_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_poly_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munstacked_y\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m2666\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mstandardized_X_poly_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2116\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2118\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2120\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m    247\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [31717, 2964]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_poly_train, y_poly_test = train_test_split(X_poly, unstacked_y,  random_state= 2666)\n",
    "scaler = MinMaxScaler()\n",
    "standardized_X_poly_train = scaler.fit_transform(X_train)\n",
    "standardized_X_poly_test = scaler.transform(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "alpha_list = [0.0000001,0.0000001, 0.001, 0.005, 0.01, 0.1]\n",
    "mselist = []\n",
    "\n",
    "for alpha in alpha_list:\n",
    "    linlasso = Ridge(alpha, max_iter = 20000).fit(standardized_X_poly_train, y_poly_train)\n",
    "    y_pred = linlasso.predict(standardized_X_poly_test)\n",
    "    mse = mean_squared_error(y_poly_test, y_pred)\n",
    "    mselist.append(mse)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.02100767569715769,\n",
       " 0.02100767569715769,\n",
       " 0.027472651047290447,\n",
       " 0.028532448157811145,\n",
       " 0.029059752409476017,\n",
       " 0.030546507016760933]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mselist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "linlasso = Ridge(0.0000001, max_iter = 10000).fit(standardized_X_poly_train, y_poly_train)\n",
    "y_pred = linlasso.predict(standardized_X_poly_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02100767569715769"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mean_squared_error(y_poly_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = pd.read_csv(\"Trout_testing_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = ans[['Date_Time', \"Water_Temp_C\", 'Depth_m']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict.pivot(index='Date_Time', columns='Depth_m', values='Water_Temp_C')\n",
    "predict= predict.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = predict[lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Depth_m</th>\n",
       "      <th>6.5</th>\n",
       "      <th>7.5</th>\n",
       "      <th>8.5</th>\n",
       "      <th>9.5</th>\n",
       "      <th>11.5</th>\n",
       "      <th>12.5</th>\n",
       "      <th>14.5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date_Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-04-20 00:00:00</th>\n",
       "      <td>0.989</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.453</td>\n",
       "      <td>1.561</td>\n",
       "      <td>1.534</td>\n",
       "      <td>1.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20 01:00:00</th>\n",
       "      <td>0.989</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.453</td>\n",
       "      <td>1.561</td>\n",
       "      <td>1.534</td>\n",
       "      <td>1.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20 02:00:00</th>\n",
       "      <td>0.989</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.453</td>\n",
       "      <td>1.561</td>\n",
       "      <td>1.534</td>\n",
       "      <td>1.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20 03:00:00</th>\n",
       "      <td>0.989</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.453</td>\n",
       "      <td>1.561</td>\n",
       "      <td>1.534</td>\n",
       "      <td>1.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-20 04:00:00</th>\n",
       "      <td>0.989</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.453</td>\n",
       "      <td>1.561</td>\n",
       "      <td>1.534</td>\n",
       "      <td>1.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-19 19:00:00</th>\n",
       "      <td>3.485</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.512</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.591</td>\n",
       "      <td>3.564</td>\n",
       "      <td>3.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-19 20:00:00</th>\n",
       "      <td>3.459</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.512</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.564</td>\n",
       "      <td>3.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-19 21:00:00</th>\n",
       "      <td>3.485</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.512</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.591</td>\n",
       "      <td>3.564</td>\n",
       "      <td>3.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-19 22:00:00</th>\n",
       "      <td>3.485</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.512</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.591</td>\n",
       "      <td>3.564</td>\n",
       "      <td>3.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-19 23:00:00</th>\n",
       "      <td>3.485</td>\n",
       "      <td>3.617</td>\n",
       "      <td>3.512</td>\n",
       "      <td>3.591</td>\n",
       "      <td>3.591</td>\n",
       "      <td>3.538</td>\n",
       "      <td>3.696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Depth_m               6.5    7.5    8.5    9.5    11.5   12.5   14.5\n",
       "Date_Time                                                           \n",
       "2018-04-20 00:00:00  0.989  1.289  1.289  1.453  1.561  1.534  1.724\n",
       "2018-04-20 01:00:00  0.989  1.289  1.289  1.453  1.561  1.534  1.724\n",
       "2018-04-20 02:00:00  0.989  1.289  1.289  1.453  1.561  1.534  1.724\n",
       "2018-04-20 03:00:00  0.989  1.289  1.289  1.453  1.561  1.534  1.724\n",
       "2018-04-20 04:00:00  0.989  1.289  1.289  1.453  1.561  1.534  1.724\n",
       "...                    ...    ...    ...    ...    ...    ...    ...\n",
       "2019-04-19 19:00:00  3.485  3.617  3.512  3.617  3.591  3.564  3.696\n",
       "2019-04-19 20:00:00  3.459  3.617  3.512  3.617  3.617  3.564  3.696\n",
       "2019-04-19 21:00:00  3.485  3.617  3.512  3.617  3.591  3.564  3.696\n",
       "2019-04-19 22:00:00  3.485  3.617  3.512  3.617  3.591  3.564  3.696\n",
       "2019-04-19 23:00:00  3.485  3.617  3.512  3.591  3.591  3.538  3.696\n",
       "\n",
       "[8760 rows x 7 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly = PolynomialFeatures(degree=3)\n",
    "X_pre = poly.fit_transform(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.        ,   0.989     ,   1.289     , ...,   6.99399379,\n",
       "          7.8602642 ,   8.83383017],\n",
       "       [  1.        ,   0.989     ,   1.289     , ...,   6.99399379,\n",
       "          7.8602642 ,   8.83383017],\n",
       "       [  1.        ,   0.989     ,   1.289     , ...,   6.99399379,\n",
       "          7.8602642 ,   8.83383017],\n",
       "       ...,\n",
       "       [  1.        ,   3.485     ,   3.617     , ..., 173.51591543,\n",
       "        179.94243082, 186.60696529],\n",
       "       [  1.        ,   3.485     ,   3.617     , ..., 173.51591543,\n",
       "        179.94243082, 186.60696529],\n",
       "       [  1.        ,   3.485     ,   3.617     , ..., 170.9934923 ,\n",
       "        178.62971948, 186.60696529]])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_X_poly_pre = scaler.transform(X_pre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_pred = linlasso.predict(standardized_X_poly_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(ans_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.388327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.388327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.388327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.388327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.388327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>3.586961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>3.599167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>3.586961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>3.586961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>3.579898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0     1.388327\n",
       "1     1.388327\n",
       "2     1.388327\n",
       "3     1.388327\n",
       "4     1.388327\n",
       "...        ...\n",
       "8755  3.586961\n",
       "8756  3.599167\n",
       "8757  3.586961\n",
       "8758  3.586961\n",
       "8759  3.579898\n",
       "\n",
       "[8760 rows x 1 columns]"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'Trout_prediction2.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
